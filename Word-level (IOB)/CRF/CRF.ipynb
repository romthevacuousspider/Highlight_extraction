{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5469\n",
      "Recall: 0.4415\n",
      "Macro F1-Score: 0.4606\n",
      "Micro F1-Score: 0.6802\n",
      "Weighted F1-Score: 0.6386\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  189     9   734]\n",
      " [   10  2079  6981]\n",
      " [  244  2052 19061]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.43      0.20      0.27       932\n",
      "           I       0.50      0.23      0.31      9070\n",
      "           O       0.71      0.89      0.79     21357\n",
      "\n",
      "    accuracy                           0.68     31359\n",
      "   macro avg       0.55      0.44      0.46     31359\n",
      "weighted avg       0.64      0.68      0.64     31359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Pars the results from CRF++\n",
    "def parse_document(filepath):\n",
    "    actual_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.startswith('#') or not line.strip():\n",
    "                continue  \n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 6:\n",
    "                actual_label = parts[-2]  # last 2 elements are labels\n",
    "                predicted_label = parts[-1].split('/')[0]  # after \"/\" is confidence score\n",
    "                \n",
    "                actual_labels.append(actual_label)\n",
    "                predicted_labels.append(predicted_label)\n",
    "    \n",
    "    return actual_labels, predicted_labels\n",
    "\n",
    "# F1-score\n",
    "def calculate_metrics(actual_labels, predicted_labels):\n",
    "    precision = precision_score(actual_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(actual_labels, predicted_labels, average='macro')\n",
    "    f1_macro = f1_score(actual_labels, predicted_labels, average='macro')\n",
    "    f1_micro = f1_score(actual_labels, predicted_labels, average='micro')\n",
    "    f1_weighted = f1_score(actual_labels, predicted_labels, average='weighted')\n",
    "    cm = confusion_matrix(actual_labels, predicted_labels)\n",
    "    report = classification_report(actual_labels, predicted_labels)\n",
    "    \n",
    "    return precision, recall, f1_macro, f1_micro, f1_weighted, cm, report\n",
    "\n",
    "# File_path\n",
    "filepath = r'C:\\Users\\X-pc\\Downloads\\crf\\test_results.txt'\n",
    "actual_labels, predicted_labels = parse_document(filepath)\n",
    "precision, recall, f1_macro, f1_micro, f1_weighted, cm, report = calculate_metrics(actual_labels, predicted_labels)\n",
    "\n",
    "#unique labels\n",
    "unique_labels = list(sorted(set(actual_labels)))\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1-Score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
